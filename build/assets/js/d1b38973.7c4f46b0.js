"use strict";(globalThis.webpackChunkphysical_ai_textbook=globalThis.webpackChunkphysical_ai_textbook||[]).push([[804],{1413:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>_,frontMatter:()=>i,metadata:()=>s,toc:()=>p});var o=t(4848),r=t(8453);const i={},a="Dynamic Walking and Balance Control",s={id:"module-4-locomotion-mobility/dynamic-walking",title:"Dynamic Walking and Balance Control",description:"Introduction: From Static to Dynamic Locomotion",source:"@site/docs/module-4-locomotion-mobility/dynamic-walking.md",sourceDirName:"module-4-locomotion-mobility",slug:"/module-4-locomotion-mobility/dynamic-walking",permalink:"/book-of-physical-ai-and-humainoid-robotics-01/docs/module-4-locomotion-mobility/dynamic-walking",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-4-locomotion-mobility/dynamic-walking.md",tags:[],version:"current",frontMatter:{},sidebar:"textbookSidebar",previous:{title:"Biomechanics of Humanoid Locomotion",permalink:"/book-of-physical-ai-and-humainoid-robotics-01/docs/module-4-locomotion-mobility/biomechanics"},next:{title:"Gait Generation and Pattern Formation",permalink:"/book-of-physical-ai-and-humainoid-robotics-01/docs/module-4-locomotion-mobility/gait-generation"}},l={},p=[{value:"Introduction: From Static to Dynamic Locomotion",id:"introduction-from-static-to-dynamic-locomotion",level:2},{value:"The Dynamic Walking Paradigm",id:"the-dynamic-walking-paradigm",level:3},{value:"Balance Control Fundamentals",id:"balance-control-fundamentals",level:2},{value:"Linear Inverted Pendulum Model (LIPM)",id:"linear-inverted-pendulum-model-lipm",level:3},{value:"Preview Control for ZMP Tracking",id:"preview-control-for-zmp-tracking",level:3},{value:"Model Predictive Control (MPC) for Walking",id:"model-predictive-control-mpc-for-walking",level:3},{value:"Walking Pattern Generation",id:"walking-pattern-generation",level:2},{value:"Footstep Planning and Timing",id:"footstep-planning-and-timing",level:3},{value:"Capture Point-Based Walking",id:"capture-point-based-walking",level:3},{value:"Balance Recovery Strategies",id:"balance-recovery-strategies",level:2},{value:"Push Recovery and Disturbance Handling",id:"push-recovery-and-disturbance-handling",level:3},{value:"Advanced Walking Patterns",id:"advanced-walking-patterns",level:2},{value:"Variable Walking Speeds and Gaits",id:"variable-walking-speeds-and-gaits",level:3},{value:"Integration with ROS 2",id:"integration-with-ros-2",level:2},{value:"ROS 2 Walking Controller Node",id:"ros-2-walking-controller-node",level:3},{value:"Conclusion",id:"conclusion",level:2}];function c(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h1,{id:"dynamic-walking-and-balance-control",children:"Dynamic Walking and Balance Control"}),"\n",(0,o.jsx)(n.h2,{id:"introduction-from-static-to-dynamic-locomotion",children:"Introduction: From Static to Dynamic Locomotion"}),"\n",(0,o.jsx)(n.p,{children:"Dynamic walking represents a fundamental shift from static stability (where the robot is stable at every instant) to dynamic stability (where stability is maintained through controlled motion). Unlike static walking, where the center of mass (CoM) remains within the support polygon at all times, dynamic walking allows for controlled falling and recovery, similar to human walking. This approach enables more natural, efficient, and human-like locomotion."}),"\n",(0,o.jsx)(n.h3,{id:"the-dynamic-walking-paradigm",children:"The Dynamic Walking Paradigm"}),"\n",(0,o.jsx)(n.p,{children:"Dynamic walking is characterized by:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Controlled falling"}),": The robot leans forward and catches itself with each step"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Pendular motion"}),": CoM moves in an inverted pendulum-like pattern"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Energy efficiency"}),": Uses gravity to assist forward motion"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Natural dynamics"}),": Exploits the robot's natural mechanical properties"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"balance-control-fundamentals",children:"Balance Control Fundamentals"}),"\n",(0,o.jsx)(n.h3,{id:"linear-inverted-pendulum-model-lipm",children:"Linear Inverted Pendulum Model (LIPM)"}),"\n",(0,o.jsx)(n.p,{children:"The Linear Inverted Pendulum Model is the foundation of most dynamic walking controllers:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.integrate import odeint\n\nclass LinearInvertedPendulumModel:\n    def __init__(self, com_height=0.85, gravity=9.81):\n        self.com_height = com_height\n        self.gravity = gravity\n        self.omega = np.sqrt(gravity / com_height)  # Natural frequency\n\n    def dynamics(self, state, t, zmp_position):\n        """Dynamics of LIPM: CoM_ddot = omega^2 * (CoM - ZMP)"""\n        x, x_dot = state\n        x_ddot = self.omega**2 * (x - zmp_position)\n        return [x_dot, x_ddot]\n\n    def simulate_trajectory(self, initial_state, zmp_trajectory, time_points):\n        """Simulate CoM trajectory given ZMP reference"""\n        com_positions = []\n        com_velocities = []\n\n        current_state = initial_state\n        dt = time_points[1] - time_points[0]\n\n        for zmp in zmp_trajectory:\n            # Simple Euler integration\n            x_ddot = self.omega**2 * (current_state[0] - zmp)\n            current_state[1] += x_ddot * dt  # Update velocity\n            current_state[0] += current_state[1] * dt  # Update position\n\n            com_positions.append(current_state[0])\n            com_velocities.append(current_state[1])\n\n        return np.array(com_positions), np.array(com_velocities)\n\n    def capture_point(self, com_position, com_velocity):\n        """Calculate capture point for balance recovery"""\n        # Capture point = CoM + CoM_velocity / omega\n        capture_x = com_position + com_velocity / self.omega\n        return capture_x\n\n    def step_for_balance(self, current_capture_point, foot_position, max_step_size=0.3):\n        """Determine step location to achieve balance"""\n        step_distance = current_capture_point - foot_position\n        if abs(step_distance) > max_step_size:\n            # Scale to maximum step size\n            step_distance = np.sign(step_distance) * max_step_size\n\n        target_foot_position = foot_position + step_distance\n        return target_foot_position\n\n# Example: Simulate LIPM walking\nlipm = LinearInvertedPendulumModel(com_height=0.85)\n\n# Initial conditions\ninitial_state = [0.0, 0.0]  # x, x_dot (CoM position and velocity)\ntime_points = np.linspace(0, 2, 200)\ndt = time_points[1] - time_points[0]\n\n# Define ZMP trajectory for forward walking\nzmp_trajectory = []\ncom_x_ref = 0.0\nfor t in time_points:\n    # Forward walking with slight perturbation\n    zmp_x = com_x_ref + 0.02 * np.sin(2 * np.pi * t)  # Small oscillation\n    zmp_trajectory.append(zmp_x)\n    com_x_ref += 0.1 * dt  # Forward progression\n\ncom_positions, com_velocities = lipm.simulate_trajectory(initial_state, zmp_trajectory, time_points)\n\nprint(f"Final CoM position: {com_positions[-1]:.3f} m")\nprint(f"Final CoM velocity: {com_velocities[-1]:.3f} m/s")\nprint(f"Average forward speed: {com_positions[-1]/time_points[-1]:.3f} m/s")\n'})}),"\n",(0,o.jsx)(n.h3,{id:"preview-control-for-zmp-tracking",children:"Preview Control for ZMP Tracking"}),"\n",(0,o.jsx)(n.p,{children:"Preview control improves ZMP tracking by considering future reference:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'class PreviewController:\n    def __init__(self, com_height=0.85, gravity=9.81, dt=0.005):\n        self.com_height = com_height\n        self.gravity = gravity\n        self.omega = np.sqrt(gravity / com_height)\n        self.dt = dt\n        self.preview_horizon = 20  # Number of steps to look ahead\n\n        # Calculate preview control gains\n        self.Kx, self.Kv, self.Kpreview = self.calculate_gains()\n\n    def calculate_gains(self):\n        """Calculate optimal preview control gains using LQR"""\n        # For LIPM: x_ddot = omega^2 * (x - zmp)\n        # State: [x, x_dot], Input: zmp\n        A = np.array([[0, 1], [self.omega**2, 0]])\n        B = np.array([0, -self.omega**2])\n\n        # Discretize the system\n        I = np.eye(2)\n        Ad = I + A * self.dt\n        Bd = B * self.dt\n\n        # Cost matrices (these can be tuned)\n        Q = np.array([[10, 0], [0, 1]])  # State cost\n        R = np.array([[0.1]])            # Input cost\n\n        # Solve discrete-time LQR\n        # This is a simplified calculation - in practice, use proper DARE solver\n        K = np.array([[10.0, 2.0]])  # Simplified gains\n\n        # Calculate preview gains\n        # This is a complex calculation involving the solution of Riccati equations\n        # For simplicity, we\'ll use pre-computed values\n        Kx = 10.0\n        Kv = 2.0\n        Kpreview = np.exp(-self.omega * self.dt * np.arange(self.preview_horizon)) * 0.5\n\n        return Kx, Kv, Kpreview\n\n    def compute_zmp_command(self, com_state, zmp_reference_trajectory):\n        """Compute ZMP command using preview control"""\n        com_pos, com_vel = com_state\n\n        # Feedback terms\n        feedback_term = self.Kx * com_pos + self.Kv * com_vel\n\n        # Preview term (consider future ZMP references)\n        preview_term = 0\n        for i in range(min(self.preview_horizon, len(zmp_reference_trajectory))):\n            if i < len(zmp_reference_trajectory):\n                preview_term += self.Kpreview[i] * zmp_reference_trajectory[i]\n\n        # Total ZMP command\n        zmp_command = zmp_reference_trajectory[0] - feedback_term - preview_term\n        return zmp_command\n\n    def simulate_with_preview_control(self, initial_com_state, zmp_reference, duration=2.0):\n        """Simulate walking with preview control"""\n        num_steps = int(duration / self.dt)\n        time_points = np.linspace(0, duration, num_steps)\n\n        com_positions = [initial_com_state[0]]\n        com_velocities = [initial_com_state[1]]\n        zmp_commands = []\n\n        current_state = initial_com_state.copy()\n\n        for i in range(num_steps - 1):\n            # Get ZMP reference trajectory (current + preview horizon)\n            start_idx = i\n            end_idx = min(i + self.preview_horizon, len(zmp_reference))\n            zmp_ref_trajectory = zmp_reference[start_idx:end_idx]\n\n            # Compute ZMP command\n            zmp_cmd = self.compute_zmp_command(current_state, zmp_ref_trajectory)\n            zmp_commands.append(zmp_cmd)\n\n            # Update CoM dynamics\n            com_acc = self.omega**2 * (current_state[0] - zmp_cmd)\n            current_state[1] += com_acc * self.dt  # Update velocity\n            current_state[0] += current_state[1] * self.dt  # Update position\n\n            com_positions.append(current_state[0])\n            com_velocities.append(current_state[1])\n\n        return np.array(com_positions), np.array(com_velocities), np.array(zmp_commands)\n\n# Example: Preview control simulation\npreview_ctrl = PreviewController(com_height=0.85, dt=0.005)\n\n# Generate ZMP reference for forward walking\nduration = 2.0\ndt = 0.005\nnum_steps = int(duration / dt)\ntime_points = np.linspace(0, duration, num_steps)\nzmp_reference = 0.1 * time_points  # Forward progression\n\ncom_pos, com_vel, zmp_cmd = preview_ctrl.simulate_with_preview_control(\n    [0.0, 0.0], zmp_reference, duration\n)\n\nprint(f"Preview control simulation completed")\nprint(f"Final CoM position: {com_pos[-1]:.3f} m")\nprint(f"Final CoM velocity: {com_vel[-1]:.3f} m/s")\n'})}),"\n",(0,o.jsx)(n.h3,{id:"model-predictive-control-mpc-for-walking",children:"Model Predictive Control (MPC) for Walking"}),"\n",(0,o.jsx)(n.p,{children:"MPC provides optimal control by solving finite-horizon optimization problems:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'class WalkingMPCController:\n    def __init__(self, com_height=0.85, gravity=9.81, dt=0.01, prediction_horizon=20):\n        self.com_height = com_height\n        self.gravity = gravity\n        self.omega = np.sqrt(gravity / com_height)\n        self.dt = dt\n        self.N = prediction_horizon  # Prediction horizon\n\n        # Cost weights\n        self.Q = 10.0    # State tracking cost\n        self.R = 0.1     # Control effort cost\n        self.P = 50.0    # Terminal cost\n\n    def predict_states(self, initial_state, zmp_sequence):\n        """Predict future states given ZMP sequence"""\n        predicted_states = [initial_state]\n        current_state = initial_state.copy()\n\n        for zmp in zmp_sequence:\n            # LIPM dynamics: x_ddot = omega^2 * (x - zmp)\n            x_ddot = self.omega**2 * (current_state[0] - zmp)\n            current_state[1] += x_ddot * self.dt  # Update velocity\n            current_state[0] += current_state[1] * self.dt  # Update position\n            predicted_states.append(current_state.copy())\n\n        return np.array(predicted_states)\n\n    def compute_mpc_control(self, current_state, reference_trajectory):\n        """Compute optimal ZMP control using MPC"""\n        # For simplicity, we\'ll use a basic optimization approach\n        # In practice, this would use quadratic programming\n\n        # Linearized prediction model\n        # X = A*x + B*u where x = [CoM_pos, CoM_vel], u = ZMP\n        A = np.array([[1, self.dt], [self.omega**2 * self.dt, 1]])\n        B = np.array([[0], [-self.omega**2 * self.dt]])\n\n        # Build prediction matrices\n        Phi = np.zeros((2 * self.N, 2))  # State prediction matrix\n        Psi = np.zeros((2 * self.N, self.N))  # Input prediction matrix\n\n        A_pow = np.eye(2)\n        for i in range(self.N):\n            Phi[2*i:2*(i+1), :] = A_pow\n            for j in range(i + 1):\n                if j == i:\n                    Psi[2*i:2*(i+1), j] = B\n                else:\n                    Psi[2*i:2*(i+1), j] = A_pow @ B\n            A_pow = A @ A_pow\n\n        # Solve QP problem (simplified)\n        # Minimize: ||Y_ref - Y||_Q^2 + ||U||_R^2\n        # where Y = Phi*x + Psi*U\n\n        # For this example, we\'ll use a simplified approach\n        # In practice, use a proper QP solver like cvxpy or quadprog\n\n        # Calculate desired ZMP to track reference\n        current_pos = current_state[0]\n        desired_pos = reference_trajectory[0] if len(reference_trajectory) > 0 else current_pos\n\n        # Simple proportional control with MPC-like considerations\n        zmp_command = desired_pos - 0.5 * (current_pos - desired_pos)\n        zmp_command = current_pos - (current_pos - zmp_command) / (self.omega**2 * 0.1)\n\n        return zmp_command\n\n    def walking_pattern_generator(self, step_length=0.3, step_height=0.1, step_time=0.8):\n        """Generate walking pattern for MPC controller"""\n        # Generate ZMP trajectory for one step\n        time_steps = int(step_time / self.dt)\n        t = np.linspace(0, step_time, time_steps)\n\n        # Double support phase at beginning and end\n        double_support_time = 0.1  # 10% of step time\n        single_support_time = step_time - 2 * double_support_time\n\n        zmp_trajectory = []\n        for ti in t:\n            if ti < double_support_time:\n                # First double support - ZMP under current foot\n                zmp = 0.0\n            elif ti < double_support_time + single_support_time:\n                # Single support - ZMP moves toward next foot\n                progress = (ti - double_support_time) / single_support_time\n                zmp = step_length * progress * 0.8  # Don\'t go fully to next foot yet\n            else:\n                # Second double support - ZMP under next foot\n                zmp = step_length * 0.9  # Almost at next foot position\n\n            zmp_trajectory.append(zmp)\n\n        return np.array(zmp_trajectory)\n\n# Example: MPC-based walking\nmpc_controller = WalkingMPCController(com_height=0.85, dt=0.01)\n\n# Generate walking pattern\nwalking_pattern = mpc_controller.walking_pattern_generator(\n    step_length=0.3, step_height=0.1, step_time=0.8\n)\n\nprint(f"Generated walking pattern with {len(walking_pattern)} points")\nprint(f"ZMP range: {np.min(walking_pattern):.3f} to {np.max(walking_pattern):.3f} m")\n'})}),"\n",(0,o.jsx)(n.h2,{id:"walking-pattern-generation",children:"Walking Pattern Generation"}),"\n",(0,o.jsx)(n.h3,{id:"footstep-planning-and-timing",children:"Footstep Planning and Timing"}),"\n",(0,o.jsx)(n.p,{children:"Generating appropriate footstep patterns for stable walking:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"class FootstepPlanner:\n    def __init__(self, step_length=0.3, step_width=0.2, step_time=0.8):\n        self.step_length = step_length\n        self.step_width = step_width\n        self.step_time = step_time\n        self.nominal_width = step_width\n\n    def generate_omni_directional_steps(self, direction, num_steps=5):\n        \"\"\"Generate footsteps for omnidirectional walking\"\"\"\n        footsteps = []\n        current_pos = np.array([0.0, 0.0])\n        current_yaw = 0.0\n\n        for i in range(num_steps):\n            # Calculate step position based on direction\n            if direction == 'forward':\n                step_offset = np.array([self.step_length, 0.0])\n            elif direction == 'backward':\n                step_offset = np.array([-self.step_length, 0.0])\n            elif direction == 'left':\n                step_offset = np.array([0.0, self.step_width])\n            elif direction == 'right':\n                step_offset = np.array([0.0, -self.step_width])\n            elif direction == 'turn_left':\n                step_offset = np.array([0.0, self.step_width])\n                current_yaw += 0.2  # 0.2 rad = ~11.5 degrees\n            elif direction == 'turn_right':\n                step_offset = np.array([0.0, -self.step_width])\n                current_yaw -= 0.2\n            else:  # forward with potential lateral adjustment\n                step_offset = np.array([self.step_length, 0.0])\n\n            # Apply rotation based on current yaw\n            rotation_matrix = np.array([\n                [np.cos(current_yaw), -np.sin(current_yaw)],\n                [np.sin(current_yaw), np.cos(current_yaw)]\n            ])\n            rotated_offset = rotation_matrix @ step_offset\n\n            # Update position\n            current_pos += rotated_offset\n\n            # Add footstep with timing\n            footstep = {\n                'position': current_pos.copy(),\n                'yaw': current_yaw,\n                'timing': i * self.step_time,\n                'foot': 'left' if i % 2 == 0 else 'right',\n                'swing_height': 0.05  # 5cm swing height\n            }\n            footsteps.append(footstep)\n\n        return footsteps\n\n    def generate_walk_trajectory(self, footsteps, dt=0.01):\n        \"\"\"Generate smooth trajectory for footsteps\"\"\"\n        trajectory = []\n        time_points = []\n\n        for i, footstep in enumerate(footsteps):\n            # Calculate trajectory from previous footstep to current\n            if i == 0:\n                prev_pos = np.array([0.0, 0.0])\n            else:\n                prev_pos = footsteps[i-1]['position']\n\n            # Interpolate between steps\n            step_duration = self.step_time\n            num_interpolation_points = int(step_duration / dt)\n\n            for j in range(num_interpolation_points):\n                t = j / num_interpolation_points  # 0 to 1\n\n                # Cubic interpolation for smooth transition\n                # Position interpolation\n                current_pos = (1 - t) * prev_pos + t * footstep['position']\n\n                # Vertical trajectory (swing motion)\n                if t < 0.5:\n                    z = 0.05 * np.sin(np.pi * t)  # Upward motion\n                else:\n                    z = 0.05 * np.sin(np.pi * t)  # Downward motion\n\n                trajectory.append(np.array([current_pos[0], current_pos[1], z]))\n                time_points.append(footstep['timing'] + t * step_duration)\n\n        return np.array(trajectory), time_points\n\n    def adjust_for_balance(self, footsteps, current_com, capture_point_threshold=0.1):\n        \"\"\"Adjust footsteps based on balance considerations\"\"\"\n        adjusted_footsteps = []\n\n        for i, footstep in enumerate(footsteps):\n            # Calculate capture point relative to foot position\n            capture_point = current_com[:2] + current_com[3:5] / 4.0  # Simplified capture point calc\n            foot_pos = footstep['position']\n\n            # Calculate error\n            error = capture_point - foot_pos\n\n            # Adjust footstep if capture point is too far from foot\n            if np.linalg.norm(error) > capture_point_threshold:\n                adjusted_pos = foot_pos + 0.5 * error  # Partial correction\n                footstep['position'] = adjusted_pos\n\n            adjusted_footsteps.append(footstep)\n\n        return adjusted_footsteps\n\n    def generate_com_trajectory(self, footsteps, dt=0.01):\n        \"\"\"Generate CoM trajectory synchronized with footsteps\"\"\"\n        # Use inverted pendulum model to generate CoM trajectory\n        com_trajectory = []\n        time_points = []\n\n        # Start with initial CoM position\n        current_com = np.array([0.0, 0.0, 0.85])  # x, y, z\n        current_com_vel = np.array([0.0, 0.0, 0.0])\n\n        for footstep in footsteps:\n            # Simulate CoM motion toward footstep location\n            target_pos = footstep['position']\n            step_duration = self.step_time\n\n            # Simple inverted pendulum tracking\n            num_points = int(step_duration / dt)\n            for i in range(num_points):\n                t = i * dt\n\n                # Move CoM toward target with inverted pendulum dynamics\n                # This is a simplified model\n                error = target_pos[:2] - current_com[:2]\n                desired_velocity = 0.5 * error  # Simple proportional control\n\n                # Apply inverted pendulum dynamics\n                zmp = current_com[:2] - current_com_vel[:2] / (9.81/0.85)**0.5\n                com_acc = (9.81/0.85) * (current_com[:2] - zmp)\n\n                current_com_vel[:2] += com_acc * dt\n                current_com[:2] += current_com_vel[:2] * dt\n\n                # Keep CoM height approximately constant\n                current_com[2] = 0.85\n\n                com_trajectory.append(current_com.copy())\n                time_points.append(footstep['timing'] + t)\n\n        return np.array(com_trajectory), time_points\n\n# Example: Generate walking patterns\nfootstep_planner = FootstepPlanner(step_length=0.3, step_width=0.2, step_time=0.8)\n\n# Generate forward walking pattern\nforward_steps = footstep_planner.generate_omni_directional_steps('forward', num_steps=6)\nprint(f\"Generated {len(forward_steps)} forward footsteps\")\n\n# Generate trajectory\ntrajectory, times = footstep_planner.generate_walk_trajectory(forward_steps)\nprint(f\"Generated trajectory with {len(trajectory)} points\")\n\n# Generate CoM trajectory\ncom_trajectory, com_times = footstep_planner.generate_com_trajectory(forward_steps)\nprint(f\"Generated CoM trajectory with {len(com_trajectory)} points\")\n"})}),"\n",(0,o.jsx)(n.h3,{id:"capture-point-based-walking",children:"Capture Point-Based Walking"}),"\n",(0,o.jsx)(n.p,{children:"Using capture points for stable walking control:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'class CapturePointWalker:\n    def __init__(self, com_height=0.85, gravity=9.81, dt=0.005):\n        self.com_height = com_height\n        self.gravity = gravity\n        self.omega = np.sqrt(gravity / com_height)\n        self.dt = dt\n        self.current_state = np.array([0.0, 0.0, 0.0, 0.0])  # [x, y, x_dot, y_dot]\n\n    def capture_point(self, pos, vel):\n        """Calculate capture point for current state"""\n        cp_x = pos[0] + vel[0] / self.omega\n        cp_y = pos[1] + vel[1] / self.omega\n        return np.array([cp_x, cp_y])\n\n    def calculate_next_foot_location(self, current_capture_point, current_foot_position,\n                                   max_step_length=0.3, step_width=0.2):\n        """Calculate where to place next foot based on capture point"""\n        # Vector from current foot to capture point\n        vector_to_capture = current_capture_point - current_foot_position\n\n        # Limit step length\n        distance_to_capture = np.linalg.norm(vector_to_capture)\n        if distance_to_capture > max_step_length:\n            # Scale the vector to maximum step length\n            direction = vector_to_capture / distance_to_capture\n            target_position = current_foot_position + direction * max_step_length\n        else:\n            target_position = current_capture_point\n\n        # Add step width alternation (left/right foot)\n        # This is simplified - in practice, you\'d track which foot is swing foot\n        target_position[1] += step_width if np.random.random() > 0.5 else -step_width\n\n        return target_position\n\n    def update_state(self, zmp_position):\n        """Update CoM state based on ZMP input"""\n        pos = self.current_state[:2]\n        vel = self.current_state[2:4]\n\n        # LIPM dynamics: CoM_ddot = omega^2 * (CoM - ZMP)\n        acc = self.omega**2 * (pos - zmp_position)\n\n        # Integrate\n        new_vel = vel + acc * self.dt\n        new_pos = pos + new_vel * self.dt\n\n        self.current_state = np.concatenate([new_pos, new_vel])\n        return self.current_state\n\n    def walking_controller(self, target_velocity, current_foot_position):\n        """Generate walking controller output"""\n        current_pos = self.current_state[:2]\n        current_vel = self.current_state[2:4]\n\n        # Calculate capture point\n        current_cp = self.capture_point(current_pos, current_vel)\n\n        # Calculate desired capture point based on target velocity\n        desired_cp = current_pos + target_velocity / self.omega\n\n        # Calculate ZMP to achieve desired capture point\n        # In steady state: ZMP = CoM - CoM_velocity/omega\n        zmp_x = current_pos[0] - current_vel[0] / self.omega\n        zmp_y = current_pos[1] - current_vel[1] / self.omega\n\n        # Add feedback to track target velocity\n        zmp_x += 0.1 * (desired_cp[0] - current_cp[0])\n        zmp_y += 0.1 * (desired_cp[1] - current_cp[1])\n\n        # Calculate next foot position\n        next_foot_pos = self.calculate_next_foot_location(\n            desired_cp, current_foot_position\n        )\n\n        return np.array([zmp_x, zmp_y]), next_foot_pos\n\n    def simulate_walking(self, target_velocity, duration=5.0):\n        """Simulate walking for specified duration"""\n        num_steps = int(duration / self.dt)\n        time_points = np.linspace(0, duration, num_steps)\n\n        com_positions = []\n        com_velocities = []\n        zm_points = []\n        capture_points = []\n\n        current_foot_pos = np.array([0.0, 0.1])  # Start with right foot offset\n\n        for t in time_points:\n            # Get controller output\n            zmp, next_foot = self.walking_controller(target_velocity, current_foot_pos)\n\n            # Update robot state\n            state = self.update_state(zmp)\n\n            # Calculate capture point\n            cp = self.capture_point(state[:2], state[2:4])\n\n            # Store data\n            com_positions.append(state[:2].copy())\n            com_velocities.append(state[2:4].copy())\n            zm_points.append(zmp.copy())\n            capture_points.append(cp.copy())\n\n            # Occasionally update foot position (simplified)\n            if int(t / 0.8) != int((t - self.dt) / 0.8):  # Every 0.8 seconds\n                current_foot_pos = next_foot\n\n        return {\n            \'time\': time_points,\n            \'com_positions\': np.array(com_positions),\n            \'com_velocities\': np.array(com_velocities),\n            \'zm_points\': np.array(zm_points),\n            \'capture_points\': np.array(capture_points)\n        }\n\n# Example: Capture point walking simulation\ncp_walker = CapturePointWalker(com_height=0.85, dt=0.005)\n\n# Simulate forward walking\nresults = cp_walker.simulate_walking(target_velocity=np.array([0.2, 0.0]), duration=3.0)\n\nprint(f"Capture point walking simulation completed")\nprint(f"Final CoM position: {results[\'com_positions\'][-1]}")\nprint(f"Final CoM velocity: {results[\'com_velocities\'][-1]}")\nprint(f"Average forward speed: {results[\'com_positions\'][-1, 0] / results[\'time\'][-1]:.3f} m/s")\n'})}),"\n",(0,o.jsx)(n.h2,{id:"balance-recovery-strategies",children:"Balance Recovery Strategies"}),"\n",(0,o.jsx)(n.h3,{id:"push-recovery-and-disturbance-handling",children:"Push Recovery and Disturbance Handling"}),"\n",(0,o.jsx)(n.p,{children:"Implementing strategies to recover from external disturbances:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"class BalanceRecoverySystem:\n    def __init__(self, com_height=0.85, gravity=9.81, max_step_length=0.3):\n        self.com_height = com_height\n        self.gravity = gravity\n        self.omega = np.sqrt(gravity / com_height)\n        self.max_step_length = max_step_length\n        self.state_history = []\n\n    def detect_disturbance(self, current_com, current_com_vel, threshold=0.5):\n        \"\"\"Detect if robot is experiencing a disturbance\"\"\"\n        # Calculate capture point\n        capture_point = current_com[:2] + current_com_vel[:2] / self.omega\n\n        # Check if capture point is outside safe region\n        # For now, assume safe region is around current foot position\n        # This is simplified - in practice, you'd know foot positions\n        distance_to_safe_zone = np.linalg.norm(capture_point)\n\n        return distance_to_safe_zone > threshold\n\n    def recovery_strategy_selection(self, capture_point, foot_positions):\n        \"\"\"Select appropriate recovery strategy based on capture point location\"\"\"\n        strategies = []\n\n        for foot_pos in foot_positions:\n            vector_to_foot = foot_pos - capture_point\n            distance = np.linalg.norm(vector_to_foot)\n\n            if distance < 0.1:  # Capture point near foot - stable\n                continue\n            elif distance < self.max_step_length:  # Can step to recover\n                strategies.append({\n                    'type': 'stepping',\n                    'target': foot_pos,\n                    'effort': distance,\n                    'feasibility': 1.0\n                })\n            else:  # Capture point too far - need more aggressive recovery\n                strategies.append({\n                    'type': 'arm_swing',\n                    'target': capture_point,\n                    'effort': distance * 2,  # Higher effort\n                    'feasibility': 0.5  # Less feasible\n                })\n\n        # Return strategy with lowest effort and highest feasibility\n        if strategies:\n            best_strategy = min(strategies, key=lambda x: x['effort'] / x['feasibility'])\n            return best_strategy\n        else:\n            return {'type': 'stable', 'target': capture_point, 'effort': 0, 'feasibility': 1.0}\n\n    def stepping_recovery(self, current_com, current_com_vel, support_foot_pos):\n        \"\"\"Calculate stepping recovery motion\"\"\"\n        # Calculate capture point\n        capture_point = current_com[:2] + current_com_vel[:2] / self.omega\n\n        # Calculate step location\n        step_vector = capture_point - support_foot_pos\n        step_distance = np.linalg.norm(step_vector)\n\n        if step_distance > self.max_step_length:\n            # Scale to maximum step length\n            step_direction = step_vector / step_distance\n            target_step_pos = support_foot_pos + step_direction * self.max_step_length\n        else:\n            target_step_pos = capture_point\n\n        # Calculate required step timing\n        # For single support time of 0.8 seconds, plan step accordingly\n        step_timing = 0.4  # Step in 0.4 seconds\n\n        return {\n            'step_position': target_step_pos,\n            'step_timing': step_timing,\n            'capture_point': capture_point,\n            'step_required': step_distance > 0.05  # Step if needed\n        }\n\n    def arm_swing_recovery(self, current_com, current_com_vel, desired_com_pos):\n        \"\"\"Calculate arm swing to modify capture point\"\"\"\n        # Arm swing can modify angular momentum and thus capture point\n        # This is a simplified model\n        current_cp = current_com[:2] + current_com_vel[:2] / self.omega\n\n        # Calculate desired arm motion to shift capture point\n        cp_correction = desired_com_pos - current_cp\n        arm_torque_requirement = cp_correction * self.omega**2 * 0.1  # Simplified\n\n        return {\n            'arm_torque_request': arm_torque_requirement,\n            'desired_cp_shift': cp_correction,\n            'feasibility': min(1.0, np.linalg.norm(cp_correction) / 0.2)  # 20cm max arm effect\n        }\n\n    def ankle_strategy(self, current_com, current_com_vel, foot_pos):\n        \"\"\"Ankle strategy for small disturbances\"\"\"\n        # Calculate required ankle torque for small adjustments\n        current_cp = current_com[:2] + current_com_vel[:2] / self.omega\n        error = current_cp - foot_pos\n\n        # Simple ankle stiffness model\n        ankle_torque = -500 * error - 50 * current_com_vel[:2]  # PD control\n\n        return {\n            'ankle_torque': ankle_torque,\n            'max_correction': 0.05,  # 5cm max ankle strategy correction\n            'applicable': np.linalg.norm(error) < 0.05  # Only for small errors\n        }\n\n    def integrated_recovery(self, current_state, foot_positions):\n        \"\"\"Integrate multiple recovery strategies\"\"\"\n        current_com = current_state[:3]\n        current_com_vel = current_state[3:6]\n\n        # Check for disturbances\n        if self.detect_disturbance(current_com, current_com_vel[:2]):\n            # Select and execute recovery strategy\n            strategy = self.recovery_strategy_selection(\n                current_com[:2] + current_com_vel[:2] / self.omega,\n                foot_positions\n            )\n\n            if strategy['type'] == 'stepping':\n                recovery_action = self.stepping_recovery(\n                    current_com[:2], current_com_vel[:2], foot_positions[0]\n                )\n            elif strategy['type'] == 'arm_swing':\n                recovery_action = self.arm_swing_recovery(\n                    current_com[:2], current_com_vel[:2], strategy['target']\n                )\n            else:\n                recovery_action = self.ankle_strategy(\n                    current_com[:2], current_com_vel[:2], foot_positions[0]\n                )\n\n            return {\n                'strategy': strategy['type'],\n                'action': recovery_action,\n                'required': True\n            }\n        else:\n            return {\n                'strategy': 'none',\n                'action': None,\n                'required': False\n            }\n\n# Example: Balance recovery simulation\nrecovery_system = BalanceRecoverySystem(com_height=0.85)\n\n# Simulate recovery from disturbance\ncurrent_state = np.array([0.0, 0.0, 0.85, 0.5, 0.0, 0.0])  # CoM position and velocity\nfoot_positions = [np.array([0.0, 0.1]), np.array([0.0, -0.1])]  # Left and right foot\n\nrecovery_result = recovery_system.integrated_recovery(current_state, foot_positions)\nprint(f\"Balance recovery needed: {recovery_result['required']}\")\nif recovery_result['required']:\n    print(f\"Strategy: {recovery_result['strategy']}\")\n    print(f\"Action details: {recovery_result['action']}\")\n"})}),"\n",(0,o.jsx)(n.h2,{id:"advanced-walking-patterns",children:"Advanced Walking Patterns"}),"\n",(0,o.jsx)(n.h3,{id:"variable-walking-speeds-and-gaits",children:"Variable Walking Speeds and Gaits"}),"\n",(0,o.jsx)(n.p,{children:"Implementing walking controllers that adapt to different speeds:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"class AdaptiveWalkingController:\n    def __init__(self, com_height=0.85, gravity=9.81):\n        self.com_height = com_height\n        self.gravity = gravity\n        self.omega = np.sqrt(gravity / com_height)\n        self.base_step_time = 0.8\n        self.base_step_length = 0.3\n\n    def calculate_gait_parameters(self, desired_speed):\n        \"\"\"Calculate gait parameters based on desired speed\"\"\"\n        # Empirical relationships for human-like gait\n        if desired_speed < 0.3:  # Very slow\n            step_length = self.base_step_length * (desired_speed / 0.3)\n            step_time = self.base_step_time * (0.3 / desired_speed) if desired_speed > 0 else self.base_step_time\n            duty_factor = 0.7  # More stance time for stability\n        elif desired_speed < 1.0:  # Normal walking\n            step_length = self.base_step_length * (0.7 + 0.3 * desired_speed)\n            step_time = self.base_step_time * (1.0 - 0.2 * (desired_speed - 0.3)) if desired_speed > 0.3 else self.base_step_time\n            duty_factor = 0.6\n        elif desired_speed < 2.0:  # Fast walking\n            step_length = self.base_step_length * (0.9 + 0.5 * desired_speed)\n            step_time = self.base_step_time * (0.8 - 0.3 * (desired_speed - 1.0))\n            duty_factor = 0.4  # Less stance time\n        else:  # Running-like\n            step_length = self.base_step_length * (1.4 + 0.3 * desired_speed)\n            step_time = self.base_step_time * (0.5 - 0.1 * min(desired_speed - 2.0, 1.0))\n            duty_factor = 0.3\n\n        # Constrain parameters\n        step_time = max(0.4, step_time)  # Minimum step time\n        step_length = min(0.6, step_length)  # Maximum step length\n\n        return {\n            'step_length': step_length,\n            'step_time': step_time,\n            'duty_factor': duty_factor,\n            'step_frequency': 1.0 / step_time if step_time > 0 else 0\n        }\n\n    def generate_speed_adaptive_pattern(self, desired_speed, duration=2.0):\n        \"\"\"Generate walking pattern adapted to desired speed\"\"\"\n        gait_params = self.calculate_gait_parameters(desired_speed)\n\n        # Generate footsteps based on parameters\n        step_time = gait_params['step_time']\n        num_steps = int(duration / step_time)\n        step_length = gait_params['step_length']\n\n        footsteps = []\n        current_pos = 0.0\n        current_lat = 0.1  # Start with right foot\n\n        for i in range(num_steps):\n            foot_pos = np.array([current_pos, current_lat, 0.0])\n            foot_timing = i * step_time\n\n            footsteps.append({\n                'position': foot_pos,\n                'timing': foot_timing,\n                'foot': 'right' if i % 2 == 0 else 'left',\n                'step_length': step_length\n            })\n\n            # Update for next step\n            current_pos += step_length\n            current_lat = -current_lat  # Alternate feet\n\n        # Generate CoM trajectory synchronized with footsteps\n        dt = 0.005\n        num_points = int(duration / dt)\n        time_points = np.linspace(0, duration, num_points)\n\n        com_trajectory = []\n        for t in time_points:\n            # Calculate phase in gait cycle\n            cycle_time = t % (2 * step_time)  # Two steps per cycle\n            cycle_phase = cycle_time / (2 * step_time)\n\n            # CoM follows forward progression with oscillation\n            forward_pos = desired_speed * t\n            lateral_osc = 0.02 * np.sin(2 * np.pi * t / step_time)  # Lateral sway\n            vertical_osc = 0.85 + 0.01 * np.sin(4 * np.pi * t / step_time)  # Vertical oscillation\n\n            com_trajectory.append(np.array([forward_pos, lateral_osc, vertical_osc]))\n\n        return footsteps, np.array(com_trajectory), gait_params\n\n    def smooth_speed_transitions(self, current_speed, target_speed, transition_time=1.0):\n        \"\"\"Generate smooth transition between different walking speeds\"\"\"\n        dt = 0.01\n        num_steps = int(transition_time / dt)\n        time_points = np.linspace(0, transition_time, num_steps)\n\n        # Create speed profile (e.g., cosine transition)\n        speed_profile = []\n        for t in time_points:\n            # Cosine interpolation between current and target speed\n            progress = 0.5 * (1 - np.cos(np.pi * t / transition_time))\n            speed = current_speed + progress * (target_speed - current_speed)\n            speed_profile.append(speed)\n\n        # Generate trajectories for each speed in the profile\n        transition_trajectories = []\n        for speed in speed_profile:\n            _, com_traj, params = self.generate_speed_adaptive_pattern(speed, dt)\n            transition_trajectories.append({\n                'speed': speed,\n                'com_trajectory': com_traj,\n                'gait_params': params\n            })\n\n        return transition_trajectories\n\n    def terrain_adaptive_walking(self, base_speed, terrain_slope, terrain_roughness):\n        \"\"\"Adjust walking for different terrain conditions\"\"\"\n        # Adjust parameters based on terrain\n        speed_factor = 1.0\n        step_factor = 1.0\n\n        # Slope effects\n        if abs(terrain_slope) > 0.1:  # Steep slope\n            speed_factor *= 0.7  # Slow down\n            step_factor *= 0.8  # Shorter steps\n        elif abs(terrain_slope) > 0.05:  # Moderate slope\n            speed_factor *= 0.9\n\n        # Roughness effects\n        if terrain_roughness > 0.05:  # Rough terrain\n            speed_factor *= 0.8\n            step_factor *= 0.9\n\n        adjusted_speed = base_speed * speed_factor\n\n        return self.generate_speed_adaptive_pattern(adjusted_speed)\n\n# Example: Adaptive walking\nadaptive_ctrl = AdaptiveWalkingController(com_height=0.85)\n\n# Test different speeds\nspeeds = [0.5, 1.0, 1.5]\nfor speed in speeds:\n    footsteps, com_traj, params = adaptive_ctrl.generate_speed_adaptive_pattern(speed, duration=1.0)\n    print(f\"Speed {speed} m/s: Step length = {params['step_length']:.3f} m, \"\n          f\"Step time = {params['step_time']:.3f} s, Frequency = {params['step_frequency']:.2f} Hz\")\n\n# Test terrain adaptation\nflat_terrain = adaptive_ctrl.terrain_adaptive_walking(1.0, 0.0, 0.01)\nslope_terrain = adaptive_ctrl.terrain_adaptive_walking(1.0, 0.1, 0.01)\nrough_terrain = adaptive_ctrl.terrain_adaptive_walking(1.0, 0.0, 0.1)\n\nprint(f\"\\nTerrain adaptation results:\")\nprint(f\"Flat: Speed factor = 1.0 (no adjustment)\")\nprint(f\"Slope: Speed factor = 0.7 (reduced for safety)\")\nprint(f\"Rough: Speed factor = 0.8 (reduced for stability)\")\n"})}),"\n",(0,o.jsx)(n.h2,{id:"integration-with-ros-2",children:"Integration with ROS 2"}),"\n",(0,o.jsx)(n.h3,{id:"ros-2-walking-controller-node",children:"ROS 2 Walking Controller Node"}),"\n",(0,o.jsx)(n.p,{children:"Integrating dynamic walking with ROS 2 for real-world deployment:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import JointState\nfrom geometry_msgs.msg import Point, Vector3\nfrom std_msgs.msg import Float64MultiArray, Bool\nfrom nav_msgs.msg import Path\nfrom geometry_msgs.msg import PoseStamped, Twist\n\nclass WalkingControllerNode(Node):\n    def __init__(self):\n        super().__init__(\'walking_controller\')\n\n        # Publishers\n        self.joint_cmd_pub = self.create_publisher(Float64MultiArray, \'/joint_commands\', 10)\n        self.com_pub = self.create_publisher(Point, \'/center_of_mass\', 10)\n        self.zmp_pub = self.create_publisher(Point, \'/zero_moment_point\', 10)\n        self.path_pub = self.create_publisher(Path, \'/walking_path\', 10)\n        self.status_pub = self.create_publisher(Bool, \'/walking_active\', 10)\n\n        # Subscribers\n        self.joint_state_sub = self.create_subscription(\n            JointState, \'/joint_states\', self.joint_state_callback, 10\n        )\n        self.imu_sub = self.create_subscription(\n            Point, \'/imu_com\', self.imu_callback, 10\n        )\n        self.foot_contact_sub = self.create_subscription(\n            Bool, \'/left_foot_contact\', self.left_foot_contact_callback, 10\n        )\n        self.velocity_cmd_sub = self.create_subscription(\n            Twist, \'/cmd_vel\', self.velocity_command_callback, 10\n        )\n\n        # Initialize walking controller\n        self.lipm_controller = LinearInvertedPendulumModel(com_height=0.85)\n        self.footstep_planner = FootstepPlanner()\n        self.balance_recovery = BalanceRecoverySystem()\n        self.adaptive_ctrl = AdaptiveWalkingController()\n\n        # Walking state\n        self.current_com = np.array([0.0, 0.0, 0.85])\n        self.current_com_vel = np.array([0.0, 0.0, 0.0])\n        self.left_foot_contact = False\n        self.right_foot_contact = False\n        self.walking_active = False\n        self.desired_velocity = np.array([0.0, 0.0])\n\n        # Timer for walking control\n        self.walk_timer = self.create_timer(0.005, self.walk_control_loop)  # 200Hz\n\n        self.get_logger().info(\'Walking controller initialized\')\n\n    def joint_state_callback(self, msg):\n        """Process joint state messages"""\n        # Extract joint positions and velocities\n        # This would interface with forward kinematics to get CoM state\n        pass\n\n    def imu_callback(self, msg):\n        """Process IMU-based CoM estimate"""\n        self.current_com = np.array([msg.x, msg.y, msg.z])\n\n    def left_foot_contact_callback(self, msg):\n        """Process left foot contact sensor"""\n        self.left_foot_contact = msg.data\n\n    def velocity_command_callback(self, msg):\n        """Process velocity commands"""\n        self.desired_velocity = np.array([msg.linear.x, msg.linear.y])\n        if np.linalg.norm(self.desired_velocity) > 0.01:\n            self.walking_active = True\n        else:\n            self.walking_active = False\n\n    def walk_control_loop(self):\n        """Main walking control loop"""\n        if not self.walking_active:\n            # Publish zero commands when not walking\n            cmd_msg = Float64MultiArray()\n            cmd_msg.data = [0.0] * 28  # Assuming 28 joints\n            self.joint_cmd_pub.publish(cmd_msg)\n            return\n\n        # Calculate ZMP command based on desired velocity\n        current_state = [self.current_com[0], self.current_com_vel[0]]\n\n        # Simple control: track desired velocity\n        desired_zmp = self.current_com[0] - self.desired_velocity[0] / self.lipm_controller.omega\n\n        # Add feedback for balance\n        current_zmp = self.current_com[0] - self.current_com_vel[0] / self.lipm_controller.omega\n        feedback_correction = 0.1 * (desired_zmp - current_zmp)\n        zmp_command = current_zmp + feedback_correction\n\n        # Publish ZMP\n        zmp_msg = Point()\n        zmp_msg.x = float(zmp_command)\n        zmp_msg.y = float(self.current_com[1] - self.current_com_vel[1] / self.lipm_controller.omega)\n        zmp_msg.z = 0.0\n        self.zmp_pub.publish(zmp_msg)\n\n        # Plan footsteps based on walking direction\n        footsteps = self.footstep_planner.generate_omni_directional_steps(\n            \'forward\', num_steps=3\n        )\n\n        # Generate joint commands based on walking pattern\n        # This would involve inverse kinematics and whole-body control\n        joint_commands = self.generate_joint_commands(footsteps)\n\n        # Publish joint commands\n        cmd_msg = Float64MultiArray()\n        cmd_msg.data = joint_commands\n        self.joint_cmd_pub.publish(cmd_msg)\n\n        # Publish CoM\n        com_msg = Point()\n        com_msg.x = float(self.current_com[0])\n        com_msg.y = float(self.current_com[1])\n        com_msg.z = float(self.current_com[2])\n        self.com_pub.publish(com_msg)\n\n        # Publish walking status\n        status_msg = Bool()\n        status_msg.data = self.walking_active\n        self.status_pub.publish(status_msg)\n\n    def generate_joint_commands(self, footsteps):\n        """Generate joint commands for walking"""\n        # This would implement inverse kinematics for walking\n        # For now, return placeholder values\n        num_joints = 28  # Example for humanoid robot\n        commands = [0.0] * num_joints\n\n        # Add walking-specific joint angles\n        # This is a simplified example - real implementation would be much more complex\n        phase = self.get_clock().now().nanoseconds / 1e9  # Use time as phase reference\n        hip_angle = 0.1 * np.sin(phase * 2 * np.pi / 0.8)  # 0.8s step period\n        knee_angle = 0.05 * np.cos(phase * 2 * np.pi / 0.8)\n\n        # Assign to appropriate joints (indices would depend on robot)\n        commands[0] = hip_angle  # Left hip\n        commands[1] = knee_angle  # Left knee\n        commands[14] = -hip_angle  # Right hip (opposite phase)\n        commands[15] = -knee_angle  # Right knee\n\n        return commands\n\n    def calculate_foot_placement(self):\n        """Calculate optimal foot placement for balance"""\n        # Calculate capture point\n        capture_point = self.current_com[:2] + self.current_com_vel[:2] / self.lipm_controller.omega\n\n        # Determine if step is needed for balance\n        if self.left_foot_contact and self.right_foot_contact:\n            # Double support - no stepping needed\n            return None\n\n        # Calculate step location based on capture point\n        support_foot_pos = self.get_support_foot_position()\n        step_location = self.balance_recovery.calculate_next_foot_location(\n            capture_point, support_foot_pos\n        )\n\n        return step_location\n\n    def get_support_foot_position(self):\n        """Get current support foot position"""\n        # This would use forward kinematics\n        # For now, return a placeholder\n        if self.left_foot_contact and not self.right_foot_contact:\n            return np.array([0.0, 0.1])  # Left foot position\n        elif self.right_foot_contact and not self.left_foot_contact:\n            return np.array([0.0, -0.1])  # Right foot position\n        else:\n            return np.array([0.0, 0.0])  # Center position\n\ndef main(args=None):\n    rclpy.init(args=args)\n    walking_node = WalkingControllerNode()\n\n    try:\n        rclpy.spin(walking_node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        walking_node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,o.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,o.jsx)(n.p,{children:"Dynamic walking and balance control represent the cutting edge of humanoid locomotion research. The combination of inverted pendulum models, capture point theory, and advanced control strategies enables robots to walk with human-like stability and efficiency. The Linear Inverted Pendulum Model provides a computationally efficient framework for balance control, while preview control and model predictive control offer sophisticated approaches to handle complex walking patterns."}),"\n",(0,o.jsx)(n.p,{children:"Balance recovery strategies ensure that robots can respond appropriately to disturbances, maintaining stability through stepping, arm swinging, or ankle strategies. The integration of these control systems with ROS 2 enables deployment in real-world applications, where robots must adapt to varying terrains and unexpected perturbations."}),"\n",(0,o.jsx)(n.p,{children:"The next section will explore gait generation and pattern formation, building on these dynamic control foundations to create natural, efficient walking patterns."})]})}function _(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>s});var o=t(6540);const r={},i=o.createContext(r);function a(e){const n=o.useContext(i);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),o.createElement(i.Provider,{value:n},e.children)}}}]);